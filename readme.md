# ğŸ›’ Kafka + Spark Streaming - Processamento de Vendas E-commerce

DescriÃ§Ã£o do Projeto
Este projeto simula o consumo de dados de vendas de um e-commerce utilizando:

* Apache Kafka (mensageria)

* Apache Spark Structured Streaming (processamento em tempo real)

O objetivo Ã© consumir as vendas publicadas no Kafka, processar o JSON recebido, explodir os produtos vendidos e calcular a quantidade total vendida por produto.

# ğŸ“¦ Tecnologias Utilizadas

* Python 3.x
* Apache Kafka
* Apache Spark (pyspark)
* Kafka-Python (para o producer)
* pyspark.sql (para o consumer)

# ğŸ—„ï¸ Estrutura dos Dados

Cada mensagem no Kafka segue o seguinte schema (em JSON):

{
  "id_ordem": "string",
  "cpf_cliente": "string",
  "produtos_comprados": ["produto1", "produto2"],
  "quantidade_por_produto": { "produto1": 1, "produto2": 2 },
  "valor_total": 1000,
  "data_hora": "2025-06-10T12:34:56"
}

# âš™ï¸ Como Rodar o Projeto

## 1ï¸âƒ£ Subir o Kafka

```
# Start Zookeeper
bin/zookeeper-server-start.sh config/zookeeper.properties

# Start Kafka
bin/kafka-server-start.sh config/server.properties

```
## 2ï¸âƒ£ Criar o tÃ³pico Kafka

```
bin/kafka-topics.sh --create --topic vendas-ecommerce --bootstrap-server localhost:9092 --partitions 1 --replication-factor 1

```
## 3ï¸âƒ£ Rodar o Producer (Gerador de vendas)

```
python produtor_vendas.py

```
## 4ï¸âƒ£ Rodar o Consumer (Spark Streaming)

```
spark-submit --packages org.apache.spark:spark-sql-kafka-0-10_2.12:3.5.1 consumidor_vendas.py

```

# ğŸš€ LÃ³gica de Processamento

1. Spark lÃª as mensagens do Kafka no tÃ³pico vendas-ecommerce
2. Faz o parsing do JSON recebido.
3. Explode o array de produtos vendidos.
4. Para cada produto, obtÃ©m a quantidade vendida.
5. Agrupa por produto e calcula a soma total de cada produto vendido.
6. Exibe os resultados no console.

# ğŸ“Š Exemplo de SaÃ­da

+----------+----------------+
|produto   |quantidade_total|
+----------+----------------+
|Headset   |25              |
|Mouse     |31              |
|Notebook  |15              |
|Monitor   |7               |
|Impressora|26              |
|Teclado   |33              |
+----------+----------------+

# âœ… Requisitos

* Kafka e Zookeeper rodando
* Spark configurado e funcionando
* DependÃªncias Python instaladas (separar em um requirements.txt se quiser deixar redondo)
